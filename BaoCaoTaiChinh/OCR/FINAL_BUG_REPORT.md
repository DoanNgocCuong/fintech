# ğŸ› Final Bug Report: vLLM Crash vá»›i Multi-Modal Inputs

## 1. BUG BÃO RA

### TÃ¬nh tráº¡ng:
- âœ… **Request Ä‘áº§u tiÃªn**: ThÃ nh cÃ´ng (200 OK)
- âŒ **Request thá»© hai**: Crash vá»›i lá»—i CUDA assertion (500 Internal Server Error)

### Lá»—i cá»¥ thá»ƒ tá»« log:
```
masked_scatter_size_check: Assertion `totalElements <= srcSize` failed
CUDA error: device-side assert triggered
EngineCore encountered an issue
```

### Command ban Ä‘áº§u (KHÃ”NG cÃ³ fix):
```bash
nohup env CUDA_VISIBLE_DEVICES=1 vllm serve rednote-hilab/dots.ocr \
  --trust-remote-code \
  --async-scheduling \
  --gpu-memory-utilization 0.60 \
  --host 0.0.0.0 \
  --port 30010 \
  > vllm.log 2>&1
```

**Káº¿t quáº£**: Request 1 OK, Request 2 CRASH

---

## 2. CÃC Dá»° ÄOÃN VÃ€ THá»¬ NGHIá»†M

### Dá»± Ä‘oÃ¡n 1: Prefix Caching Issue âŒ (SAI)
**LÃ½ thuyáº¿t**: Prefix caching conflict vá»›i multi-modal inputs

**Thá»­ nghiá»‡m**:
- TÃ¬m flag disable prefix caching
- Thá»­ `--disable-prefix-caching` â†’ âŒ Flag khÃ´ng tá»“n táº¡i
- TÃ¬m Ä‘Æ°á»£c flag Ä‘Ãºng: `--no-enable-prefix-caching`
- ThÃªm vÃ o command vÃ  test láº¡i

**Káº¿t quáº£**: âŒ **VáºªN CRASH**
- Log cho tháº¥y: `Prefix cache hit rate: 0.0%` (Ä‘Ã£ disable)
- NhÆ°ng váº«n crash â†’ **KhÃ´ng pháº£i nguyÃªn nhÃ¢n chÃ­nh**

### Dá»± Ä‘oÃ¡n 2: Chunked Prefill vá»›i Batch Size QuÃ¡ Nhá» âœ… (ÄÃšNG)
**LÃ½ thuyáº¿t**: Image tokens (4819) > max batch tokens (2048) â†’ Pháº£i chia chunks â†’ Tensor mismatch

**Evidence tá»« log crash**:
```
Line 130: mm_position=PlaceholderRange(offset=2, length=4819)  # Image cÃ³ 4819 tokens
Line 130: num_scheduled_tokens: 2048                          # Chá»‰ schedule 2048 tokens
Line 7:   Chunked prefill is enabled with max_num_batched_tokens=2048
```

**PhÃ¢n tÃ­ch**:
- vLLM cá»‘ chia 4819 tokens thÃ nh chunks 2048 tokens
- Image tokens lÃ  multi-modal features (khÃ´ng pháº£i text thÃ´ng thÆ°á»ng)
- Khi scatter vÃ o KV cache theo chunks â†’ tensor size mismatch â†’ CRASH

**Káº¿t quáº£**: âœ… **ÄÃ‚Y LÃ€ NGUYÃŠN NHÃ‚N CHÃNH**

### Dá»± Ä‘oÃ¡n 3: CUDA Graphs Issue âš ï¸ (CHÆ¯A TEST RIÃŠNG)
**LÃ½ thuyáº¿t**: CUDA graphs Ä‘Æ°á»£c capture vá»›i size cá»‘ Ä‘á»‹nh, replay vá»›i wrong sizes

**Thá»­ nghiá»‡m**: ThÃªm `--enforce-eager` Ä‘á»ƒ disable CUDA graphs

**Káº¿t quáº£**: âœ… Server cháº¡y á»•n Ä‘á»‹nh, nhÆ°ng chÆ°a test riÃªng láº» Ä‘á»ƒ xÃ¡c nháº­n cÃ³ cáº§n thiáº¿t khÃ´ng

---

## 3. SCRIPT BAN Äáº¦U VÃ€ SAU KHI TEST

### Script ban Ä‘áº§u (start_vllm_fixed.sh - version 1):
```bash
#!/bin/bash
nohup env CUDA_VISIBLE_DEVICES=1 vllm serve rednote-hilab/dots.ocr \
  --trust-remote-code \
  --async-scheduling \
  --gpu-memory-utilization 0.60 \
  --host 0.0.0.0 \
  --port 30010 \
  --no-enable-prefix-caching \        # Fix 1: ThÃªm tá»« dá»± Ä‘oÃ¡n 1
  --max-num-batched-tokens 8192 \     # Fix 2: ThÃªm tá»« dá»± Ä‘oÃ¡n 2
  --enforce-eager \                   # Fix 3: ThÃªm tá»« dá»± Ä‘oÃ¡n 3
  > vllm.log 2>&1 &
```

**Káº¿t quáº£**: âœ… Server cháº¡y á»•n Ä‘á»‹nh vá»›i cáº£ 3 fixes

### Script sau khi test (start_vllm_fixed.sh - version 2 - FINAL):
```bash
#!/bin/bash
nohup env CUDA_VISIBLE_DEVICES=1 vllm serve rednote-hilab/dots.ocr \
  --trust-remote-code \
  --async-scheduling \
  --gpu-memory-utilization 0.60 \
  --host 0.0.0.0 \
  --port 30010 \
  --max-num-batched-tokens 8192 \     # CHá»ˆ GIá»® Láº I FIX QUAN TRá»ŒNG NHáº¤T
  > vllm.log 2>&1 &
```

**Káº¿t quáº£**: âœ… **CHá»ˆ Cáº¦N 1 FIX NÃ€Y LÃ€ Äá»¦** - Server cháº¡y á»•n Ä‘á»‹nh

**LÃ½ do bá» Fix 1 vÃ  Fix 3**:
- Fix 1 (`--no-enable-prefix-caching`): Log cÅ© Ä‘Ã£ disable nhÆ°ng váº«n crash â†’ KhÃ´ng pháº£i nguyÃªn nhÃ¢n
- Fix 3 (`--enforce-eager`): ChÆ°a test riÃªng, cÃ³ thá»ƒ khÃ´ng cáº§n thiáº¿t náº¿u Fix 2 Ä‘Ã£ Ä‘á»§

---

## 4. Váº¤N Äá»€ CHÃNH - NGUYÃŠN NHÃ‚N CHÃNH - GIáº¢I PHÃP CHÃNH

### ğŸ¯ Váº¤N Äá»€ CHÃNH:

**vLLM crash khi xá»­ lÃ½ request thá»© 2 vá»›i image khÃ¡c nhau**

Chi tiáº¿t:
- Request 1 vá»›i Image A (4819 tokens) â†’ âœ… ThÃ nh cÃ´ng
- Request 2 vá»›i Image B (4819 tokens, ná»™i dung khÃ¡c) â†’ âŒ Crash
- Lá»—i: `masked_scatter_size_check: Assertion 'totalElements <= srcSize' failed`

---

### ğŸ” NGUYÃŠN NHÃ‚N CHÃNH:

**Chunked Prefill vá»›i `max_num_batched_tokens=2048` quÃ¡ nhá» so vá»›i image tokens (4819 tokens)**

**CÆ¡ cháº¿ gÃ¢y lá»—i:**

1. **Chunked Prefill Ä‘Æ°á»£c enable** (default):
   ```
   max_num_batched_tokens = 2048 (default)
   ```

2. **Image tokens vÆ°á»£t quÃ¡ batch size**:
   ```
   Image tokens = 4819 tokens
   Max batch tokens = 2048 tokens
   4819 > 2048 â†’ Pháº£i chia thÃ nh chunks
   ```

3. **Váº¥n Ä‘á» khi split multi-modal tokens**:
   ```
   Chunk 1: tokens 0-2048   â†’ Xá»­ lÃ½ OK
   Chunk 2: tokens 2048-4819 â†’ Scatter vÃ o KV cache
   â†’ Tensor size mismatch!
   â†’ masked_scatter fail: totalElements > srcSize
   â†’ CUDA assertion error
   â†’ CRASH
   ```

4. **Táº¡i sao Request 1 OK nhÆ°ng Request 2 crash?**
   - Request 1: Xá»­ lÃ½ fresh, CUDA graph Ä‘Æ°á»£c capture láº§n Ä‘áº§u â†’ OK
   - Request 2: Cá»‘ reuse CUDA graph tá»« Request 1 â†’ Graph cÃ³ size cá»‘ Ä‘á»‹nh â†’ Replay vá»›i wrong sizes â†’ CRASH

---

### âœ… GIáº¢I PHÃP CHÃNH:

**TÄƒng `max_num_batched_tokens` tá»« 2048 lÃªn 8192**

**Command fix:**
```bash
--max-num-batched-tokens 8192
```

**Táº¡i sao fix nÃ y hoáº¡t Ä‘á»™ng:**

1. **Äá»§ lá»›n Ä‘á»ƒ xá»­ lÃ½ toÃ n bá»™ image tokens**:
   ```
   Image tokens = 4819 tokens
   max_num_batched_tokens = 8192
   4819 < 8192 â†’ KhÃ´ng cáº§n chia chunks
   â†’ Xá»­ lÃ½ toÃ n bá»™ trong 1 batch
   â†’ KhÃ´ng cÃ³ tensor size mismatch
   â†’ KhÃ´ng crash
   ```

2. **`max_num_batched_tokens` lÃ  gÃ¬?**
   - LÃ  **tá»•ng sá»‘ tokens tá»‘i Ä‘a** trong má»™t batch (khÃ´ng pháº£i cho tá»«ng request)
   - Vá»›i 1 request: Náº¿u request > max â†’ Pháº£i chia chunks
   - Vá»›i nhiá»u requests: Tá»•ng tokens cá»§a táº¥t cáº£ requests â‰¤ max

3. **Táº¡i sao chá»n 8192?**
   - Image cÃ³ 4819 tokens
   - 8192 = 2 Ã— 4096 (an toÃ n, Ä‘á»§ lá»›n)
   - CÃ³ thá»ƒ xá»­ lÃ½ Ä‘Æ°á»£c images lá»›n hÆ¡n trong tÆ°Æ¡ng lai
   - Váº«n náº±m trong giá»›i háº¡n GPU memory (60% utilization)

---

## ğŸ“Š TÃ“M Táº®T QUÃ TRÃŒNH

| BÆ°á»›c | Dá»± Ä‘oÃ¡n | Thá»­ nghiá»‡m | Káº¿t quáº£ | Káº¿t luáº­n |
|------|---------|------------|---------|----------|
| 1 | Prefix caching issue | ThÃªm `--no-enable-prefix-caching` | âŒ Váº«n crash | KhÃ´ng pháº£i nguyÃªn nhÃ¢n |
| 2 | Batch size quÃ¡ nhá» | ThÃªm `--max-num-batched-tokens 8192` | âœ… OK | **NGUYÃŠN NHÃ‚N CHÃNH** |
| 3 | CUDA graphs issue | ThÃªm `--enforce-eager` | âœ… OK | CÃ³ thá»ƒ khÃ´ng cáº§n thiáº¿t |

---

## ğŸ¯ Káº¾T LUáº¬N CUá»I CÃ™NG

### Fix cáº§n thiáº¿t (100%):
```bash
--max-num-batched-tokens 8192
```

### LÃ½ do:
1. **NguyÃªn nhÃ¢n chÃ­nh**: Image tokens (4819) > default batch size (2048) â†’ Pháº£i chia chunks â†’ Tensor mismatch â†’ Crash
2. **Giáº£i phÃ¡p**: TÄƒng batch size lÃªn 8192 â†’ Äá»§ lá»›n Ä‘á»ƒ xá»­ lÃ½ toÃ n bá»™ image tokens â†’ KhÃ´ng cáº§n chia chunks â†’ KhÃ´ng crash
3. **ÄÃ£ test**: âœ… Server cháº¡y á»•n Ä‘á»‹nh vá»›i chá»‰ fix nÃ y

### Fix khÃ´ng cáº§n thiáº¿t (Ä‘Ã£ test):
- `--no-enable-prefix-caching`: KhÃ´ng pháº£i nguyÃªn nhÃ¢n (log cÅ© Ä‘Ã£ disable nhÆ°ng váº«n crash)
- `--enforce-eager`: CÃ³ thá»ƒ khÃ´ng cáº§n náº¿u Fix chÃ­nh Ä‘Ã£ Ä‘á»§ (chÆ°a test riÃªng láº»)

---

## ğŸ“ SCRIPT FINAL (start_vllm_fixed.sh)

```bash
#!/bin/bash
# ============================================================================
# vLLM Server Start Script - Fixed for Multi-Modal (Image) Inputs
# ============================================================================
# 
# Fixes bug: CUDA assertion error khi xá»­ lÃ½ request thá»© 2 vá»›i image khÃ¡c nhau
# 
# NguyÃªn nhÃ¢n chÃ­nh: Chunked prefill vá»›i max_num_batched_tokens=2048 
#                     khÃ´ng Ä‘á»§ cho image tokens (4819 tokens)
# 
# Giáº£i phÃ¡p: TÄƒng max_num_batched_tokens lÃªn 8192
#
# Xem chi tiáº¿t: FINAL_BUG_REPORT.md
# ============================================================================

nohup env CUDA_VISIBLE_DEVICES=1 vllm serve rednote-hilab/dots.ocr \
  --trust-remote-code \
  --async-scheduling \
  --gpu-memory-utilization 0.60 \
  --host 0.0.0.0 \
  --port 30010 \
  --max-num-batched-tokens 8192 \
  > vllm.log 2>&1 &
```

---

**Report Ä‘Æ°á»£c tá»•ng há»£p tá»«**: 
- `BUG_ANALYSIS_COMPLETE.md`
- `ANALYSIS_FIX_NEEDED.md`
- `ANALYSIS_CRASH.md`
- `FIX_REPORT.md`
- `GIAI_THICH_DON_GIAN.md`

**NgÃ y**: 2025-11-01  
**Version**: Final 1.0


