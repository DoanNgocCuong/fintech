import time
import glob
import os
import logging
import threading
import concurrent.futures
from typing import List, Dict, Callable, Any

logger = logging.getLogger(__name__)

# Window time Ä‘á»ƒ group cÃ¡c requests hoÃ n thÃ nh trong cÃ¹ng má»™t wave (tá»« file test)
WINDOW_S = 5.0  # window to group the first completion wave

def estimate_concurrency_by_first_wave(end_times: List[float]) -> int:
    """
    Æ¯á»›c tÃ­nh sá»‘ lÆ°á»£ng concurrent requests dá»±a trÃªn first wave completion.
    Tá»« file test: utils_test_ocr_parallel_number_workers_insted_of_locust_test.py
    """
    if not end_times:
        return 0
    first = min(end_times)
    return sum(1 for t in end_times if t <= first + WINDOW_S)

def process_images_parallel(
    list_image_paths: List[str],
    max_workers: int = 8,
    model: str = "",
    api: str = "",
    process_func: Callable = None,
) -> Dict[str, any]:
    """
    Cháº¡y OCR song song trÃªn má»™t list cÃ¡c áº£nh.

    Args:
        list_image_paths (List[str]): Danh sÃ¡ch Ä‘Æ°á»ng dáº«n tá»›i cÃ¡c file áº£nh Ä‘á»ƒ OCR.
        max_workers (int): Sá»‘ lÆ°á»£ng luá»“ng (threads) tá»‘i Ä‘a cháº¡y song song.
        model (str): TÃªn model sá»­ dá»¥ng cho OCR.
        api (str): Endpoint API Ä‘á»ƒ gá»i OCR.
        process_func (Callable): HÃ m thá»±c thi xá»­ lÃ½ OCR cho tá»«ng áº£nh, nháº­n Ä‘á»‘i sá»‘ (img_path, model, api).

    Returns:
        Dict[str, any]: 
            - results: List cÃ¡c dict gá»“m {"path": ..., "ok": bool, "start": float, "end": float, "dur": float, "err": str}
            - total_ok: Tá»•ng sá»‘ áº£nh xá»­ lÃ½ thÃ nh cÃ´ng
            - total_err: Tá»•ng sá»‘ áº£nh bá»‹ lá»—i
            - total: Tá»•ng sá»‘ áº£nh Ä‘áº§u vÃ o
            - total_dur: Tá»•ng thá»i gian xá»­ lÃ½ (giÃ¢y)
            - fastest_dur: Thá»i gian xá»­ lÃ½ nhanh nháº¥t (giÃ¢y)
            - slowest_dur: Thá»i gian xá»­ lÃ½ cháº­m nháº¥t (giÃ¢y)
            - approx_conc: Æ¯á»›c tÃ­nh sá»‘ lÆ°á»£ng concurrent requests (sá»‘ lÆ°á»£ng báº¯n song song)
    """
    if process_func is None:
        # Import hÃ m xá»­ lÃ½ máº·c Ä‘á»‹nh náº¿u chÆ°a cung cáº¥p process_func.
        from main_parallel import process_single_image_ocr
        process_func = process_single_image_ocr

    results = []  # LÆ°u láº¡i káº¿t quáº£ tá»«ng áº£nh sau khi xá»­ lÃ½ {"path": ..., "ok": ...}
    start_time = time.time()  # ÄÃ¡nh dáº¥u thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u xá»­ lÃ½
    
    # Counter Ä‘á»ƒ Ä‘Ã¡nh sá»‘ task ID (thread-safe)
    task_counter = {"count": 0}
    task_counter_lock = threading.Lock()

    # Wrapper function Ä‘á»ƒ Ä‘o start time ÄÃšNG cÃ¡ch (theo pattern tá»« file test)
    def ocr_wrapper(img_path: str) -> Dict[str, Any]:
        """
        Wrapper function Ä‘á»ƒ Ä‘o start time TRÆ¯á»šC khi gá»i process_func.
        Theo pattern tá»« utils_test_ocr_parallel_number_workers_insted_of_locust_test.py
        """
        # Láº¥y task ID (thread-safe)
        with task_counter_lock:
            task_counter["count"] += 1
            task_id = task_counter["count"]
        
        file_basename = os.path.basename(img_path)
        thread_id = threading.get_ident()  # Thread ID (khÃ´ng pháº£i PID vÃ¬ dÃ¹ng threads)
        task_start = time.time()  # Äo thá»i gian báº¯t Ä‘áº§u task TRÆ¯á»šC khi gá»i process_func
        
        # Log vá»›i task ID vÃ  thread ID Ä‘á»ƒ dá»… track
        logger.info(f"ğŸš€ OCR START #{task_id}: {file_basename} | thread_id={thread_id}")
        
        ok = False
        err = ""
        try:
            # Gá»i process_func vÃ  Ä‘o thá»i gian chÃ­nh xÃ¡c
            res = process_func(img_path, model, api)
            ok = bool(res and res.strip())
        except Exception as e:
            ok = False
            err = f"{type(e).__name__}: {e}"
        
        task_end = time.time()  # Äo thá»i gian káº¿t thÃºc task
        task_dur = task_end - task_start  # TÃ­nh duration tá»« lÃºc start Ä‘áº¿n lÃºc OCR xong
        
        # Log thá»i gian duration cho tá»«ng task khi hoÃ n thiá»‡n (theo pattern tá»« file test)
        status_msg = f"âœ… OCR COMPLETED #{task_id}: {file_basename} | ok={ok} | dur={task_dur:.2f}s | thread_id={thread_id}"
        if not ok and err:
            status_msg += f" | {err}"
        logger.info(status_msg)
        
        return {
            "path": img_path,
            "task_id": task_id,
            "thread_id": thread_id,
            "ok": ok,
            "start": task_start,
            "end": task_end,
            "dur": task_dur,
            "err": err
        }

    # Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ thá»±c thi Ä‘a luá»“ng
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Gá»­i tá»«ng tÃ¡c vá»¥ xá»­ lÃ½ áº£nh lÃªn thread pool, nháº­n láº¡i future object cho tá»«ng áº£nh
        # Sá»­ dá»¥ng wrapper function Ä‘á»ƒ Ä‘o start time Ä‘Ãºng cÃ¡ch
        futures = {
            executor.submit(ocr_wrapper, img_path): img_path 
            for img_path in list_image_paths
        }

        # Duyá»‡t trÃªn cÃ¡c tÆ°Æ¡ng lai hoÃ n thÃ nh (cÃ³ thá»ƒ khÃ´ng Ä‘Ãºng thá»© tá»±)
        for future in concurrent.futures.as_completed(futures):
            # Láº¥y káº¿t quáº£ tá»« wrapper function (Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ start, end, dur, err)
            result = future.result()
            results.append(result)

    # Tá»•ng sá»‘ áº£nh thÃ nh cÃ´ng (ok=True)
    total_ok = sum(1 for r in results if r["ok"])
    # Tá»•ng sá»‘ áº£nh khÃ´ng thÃ nh cÃ´ng
    total_err = len(results) - total_ok
    
    # TÃ­nh fastest vÃ  slowest duration (theo pattern tá»« file test)
    durations = [r["dur"] for r in results if r["ok"]]
    fastest_dur = min(durations) if durations else 0
    slowest_dur = max(durations) if durations else 0
    
    # TÃ­nh approximate parallelism/concurrency (sá»‘ lÆ°á»£ng báº¯n song song)
    # Sáº¯p xáº¿p results theo end time (theo pattern tá»« file test)
    results_sorted = sorted(results, key=lambda r: r["end"])
    end_times = [r["end"] for r in results_sorted if r["ok"]]
    approx_conc = estimate_concurrency_by_first_wave(end_times)
    
    total_dur = time.time() - start_time

    # Tráº£ vá» dict chá»©a káº¿t quáº£ chi tiáº¿t cÅ©ng nhÆ° tá»•ng há»£p
    return {
        "results": results,  # Káº¿t quáº£ cho tá»«ng áº£nh (cÃ³ start, end, dur, err)
        "total_ok": total_ok,  # Sá»‘ áº£nh OK
        "total_err": total_err,  # Sá»‘ áº£nh lá»—i
        "total": len(list_image_paths),  # Tá»•ng sá»‘ áº£nh
        "total_dur": total_dur,  # Tá»•ng thá»i gian xá»­ lÃ½ (giÃ¢y)
        "fastest_dur": fastest_dur,  # Thá»i gian xá»­ lÃ½ nhanh nháº¥t (giÃ¢y)
        "slowest_dur": slowest_dur,  # Thá»i gian xá»­ lÃ½ cháº­m nháº¥t (giÃ¢y)
        "approx_conc": approx_conc,  # Æ¯á»›c tÃ­nh sá»‘ lÆ°á»£ng concurrent requests (sá»‘ lÆ°á»£ng báº¯n song song)
    }
    
def main():
    image_paths = glob.glob("/home/ubuntu/fintech/BaoCaoTaiChinh/OCR/data/out_images/*.png")
    result = process_images_parallel(
        list_image_paths=image_paths,
        max_workers=8,
        model="rednote-hilab/dots.ocr",
        api="http://103.253.20.30:30010/v1"
    )
    print(result)
    
if __name__ == "__main__":
    main()