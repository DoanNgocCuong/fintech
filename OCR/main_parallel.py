import os
import glob
import base64
import re
from pdf2image import convert_from_path
from openai import OpenAI
import logging
from markdownify import markdownify
from PIL import Image
import time
import threading
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from typing import List, Dict, Any, Callable, Optional, Tuple
import psutil

# Import utils tá»« utils_parallel_batch_size_max_worker.py
from utils_parallel_batch_size_max_worker import (
    ParallelBatchProcessor,
    process_images_parallel_optimized
)

# Cáº¥u hÃ¬nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)

PDF = "/home/ubuntu/cuong_dn/fintech/OCR/data/NgÃ nh Báº£o hiá»ƒm/BIC/2014/Bao_cao_tai_chinh/BIC_2014_1_4_1.pdf"
PDF = "/home/ubuntu/cuong_dn/fintech/OCR/data/5_pages_test.pdf"
OUT_DIR = "/home/ubuntu/cuong_dn/fintech/OCR/data/out_images"
MODEL = "rednote-hilab/dots.ocr"
API = "http://103.253.20.30:30010/v1"
OUT_MD = "data/33_pages_test.md"

# Config cho parallel processing
PDF_CONVERT_THREADS = multiprocessing.cpu_count()  # Sá»‘ cores Ä‘á»ƒ convert PDF
# OCR_MAX_WORKERS pháº£i â‰¤ server max_num_seqs (hiá»‡n táº¡i server = 8)
# NÃªn set = 8 Ä‘á»ƒ táº­n dá»¥ng tá»‘i Ä‘a server capacity
OCR_MAX_WORKERS = 20  # Sá»‘ workers cho OCR parallel (Ä‘á»“ng bá»™ vá»›i server max-num-seqs=8)

# ============================================================================
# OPTIMIZE 1: PDF -> Images vá»›i parallel conversion
# ============================================================================
def pdf2listimages(pdf_path, out_dir, thread_count=None):
    """
    Convert PDF -> Images vá»›i parallel processing
    Äáº·t tÃªn file áº£nh theo format: tÃªn_file_pdf-1.png, tÃªn_file_pdf-2.png, ...
    """
    os.makedirs(out_dir, exist_ok=True)
    
    if thread_count is None:
        thread_count = PDF_CONVERT_THREADS
    
    # Láº¥y tÃªn file PDF (khÃ´ng cÃ³ pháº§n má»Ÿ rá»™ng) Ä‘á»ƒ Ä‘áº·t tÃªn cho áº£nh
    pdf_basename = os.path.splitext(os.path.basename(pdf_path))[0]
    
    logger.info(f"ğŸ”„ Converting PDF to images with {thread_count} threads...")
    convert_start = time.time()
    
    # Convert PDF thÃ nh images vá»›i parallel processing
    convert_from_path(
        pdf_path,
        dpi=200,
        output_folder=out_dir,
        fmt="png",
        thread_count=thread_count,  # â† TÄ‚NG Tá»C: Convert pages song song
        use_pdftocairo=True  # â† TÄƒng tá»‘c: DÃ¹ng pdftocairo (nhanh hÆ¡n pdftoppm)
    )
    
    convert_time = time.time() - convert_start
    logger.info(f"âœ… PDF converted in {convert_time:.2f} seconds")
    
    # TÃ¬m vÃ  sáº¯p xáº¿p file áº£nh theo thá»i gian modify Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ãºng thá»© tá»± page
    temp_image_paths = glob.glob(f"{out_dir}/*.png")
    temp_image_paths.sort(key=lambda x: os.path.getmtime(x))
    
    # Äá»•i tÃªn cÃ¡c file áº£nh theo format: tÃªn_file_pdf-1.png, tÃªn_file_pdf-2.png, ...
    image_paths = []
    for idx, temp_path in enumerate(temp_image_paths, start=1):
        new_name = f"{pdf_basename}-{idx}.png"
        new_path = os.path.join(out_dir, new_name)
        
        try:
            os.rename(temp_path, new_path)
            image_paths.append(new_path)
        except Exception as e:
            logger.error(f"âŒ Failed to rename {temp_path} to {new_path}: {e}")
            image_paths.append(temp_path)
    
    logger.info(f"ğŸ“„ Found {len(image_paths)} images (renamed to {pdf_basename}-N.png format)")
    return image_paths

# ============================================================================
# OCR Functions
# ============================================================================
def image2text(image_path, model, api, client=None):
    """OCR image -> text (optimized: read once, no unnecessary conversions)"""
    if client is None:
        client = OpenAI(base_url=api, api_key="EMPTY", timeout=120.0)
    
    # Read file once and encode to base64
    with open(image_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    
    # Call OCR API
    resp = client.chat.completions.create(
        model=model,
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": "Extract structured markdown from this page."},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
            ],
        }],
        temperature=0.0,
        max_tokens=4096,
        timeout=120.0
    )
    
    page_text = resp.choices[0].message.content or ""
    logger.info(f"âœ… OCR: {os.path.basename(image_path)} -> {len(page_text)} chars")
    return page_text

def text2markdown(page_text):
    """Convert HTML to markdown"""
    return markdownify(page_text, heading_style="ATX")

# ============================================================================
# OPTIMIZE 2: OCR Processing Function vá»›i utils_parallel_batch_size_max_worker.py
# ============================================================================
def process_single_image_ocr(image_path: str, model: str, api: str, **kwargs) -> Optional[str]:
    """
    Process single image: OCR -> Markdown -> Save temp file -> Delete image
    Function nÃ y sáº½ Ä‘Æ°á»£c dÃ¹ng bá»Ÿi ParallelBatchProcessor
    
    Args:
        image_path: Path to image file
        model: Model name
        api: API endpoint
        **kwargs: Additional arguments (ignored)
        
    Returns:
        markdown text or None if error
    """
    try:
        # Create thread-safe client
        client = OpenAI(base_url=api, api_key="EMPTY", timeout=120.0)
        
        # OCR: image -> text -> markdown
        page_text = image2text(image_path, model, api, client)
        markdown = text2markdown(page_text)
        
        # Save temp markdown file (same name as image but .md extension)
        md_temp_path = os.path.splitext(image_path)[0] + ".md"
        with open(md_temp_path, "w", encoding="utf-8") as f:
            f.write(markdown)
        logger.debug(f"ğŸ’¾ Saved: {os.path.basename(md_temp_path)}")
        
        # Delete image after processing
        os.remove(image_path)
        logger.debug(f"ğŸ—‘ï¸  Deleted: {os.path.basename(image_path)}")
        
        return markdown
        
    except Exception as e:
        logger.error(f"âŒ Error processing {image_path}: {e}")
        return None

# ============================================================================
# Main Pipeline: PDF -> Images (parallel) -> OCR (parallel) -> Markdown
# ============================================================================
def pdf2finalmarkdown(pdf_path, out_dir, model, api, output_md, max_workers=None):
    """
    Convert PDF -> Images (parallel) -> OCR (parallel) -> Markdown
    
    Args:
        pdf_path: Path to PDF file
        out_dir: Output directory for images
        model: Model name
        api: API endpoint
        output_md: Output markdown file path
        max_workers: Max workers for OCR (None = auto-detect)
    """
    total_start = time.time()
    
    logger.info(f"ğŸš€ Start processing: {pdf_path}")
    
    # Step 1: Convert PDF -> Images (PARALLEL)
    pdf_start = time.time()
    image_paths = pdf2listimages(pdf_path, out_dir, thread_count=PDF_CONVERT_THREADS)
    pdf_time = time.time() - pdf_start
    logger.info(f"â±ï¸  PDF conversion: {pdf_time:.2f}s")
    
    if not image_paths:
        logger.error("No images generated from PDF!")
        return
    
    # Step 2: Process images -> Markdown (PARALLEL)
    # Sá»­ dá»¥ng ParallelBatchProcessor vá»›i GPU monitoring vÃ  adaptive batch processing
    ocr_start = time.time()
    logger.info(f"ğŸš€ Processing {len(image_paths)} images in parallel...")
    
    process_images_parallel_optimized(
        image_paths=image_paths,
        process_func=process_single_image_ocr,
        max_workers=max_workers or OCR_MAX_WORKERS,
        batch_size=None,  # Auto-calculate optimal batch size
        enable_gpu_monitoring=True,
        model=model,
        api=api
    )
    
    ocr_time = time.time() - ocr_start
    logger.info(f"â±ï¸  OCR processing: {ocr_time:.2f}s")
    
    # Step 3: Merge markdown tá»« cÃ¡c file táº¡m trong out_dir
    md_files_all = glob.glob(f"{out_dir}/*.md")
    
    if not md_files_all:
        logger.error("No markdown files found in output directory!")
        return
    
    # Sáº¯p xáº¿p file theo sá»‘ page (extract tá»« tÃªn file: xxx-1.md -> 1)
    def extract_page_number(filepath):
        match = re.search(r'-(\d+)\.md$', os.path.basename(filepath))
        return int(match.group(1)) if match else 0
    
    md_files = sorted(md_files_all, key=extract_page_number)
    logger.info(f"ğŸ“„ Found {len(md_files)} markdown files")
    
    # Äá»c vÃ  gá»™p táº¥t cáº£ cÃ¡c file markdown
    md_contents = []
    for md_file in md_files:
        try:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    md_contents.append(content)
        except Exception as e:
            logger.error(f"âŒ Error reading {md_file}: {e}")
    
    if not md_contents:
        logger.error("No valid markdown content found!")
        return
    
    # Gá»™p vÃ  lÆ°u file markdown cuá»‘i cÃ¹ng
    os.makedirs(os.path.dirname(output_md), exist_ok=True)
    with open(output_md, "w", encoding="utf-8") as f:
        f.write("\n\n ---\n\n".join(md_contents))
    logger.info(f"ğŸ’¾ Saved: {output_md} ({len(md_contents)} pages)")
    
    # XÃ³a cÃ¡c file markdown táº¡m
    for md_file in md_files:
        try:
            os.remove(md_file)
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to delete {md_file}: {e}")
    
    total_time = time.time() - total_start
    logger.info(f"\nğŸ¯ TOTAL TIME: {total_time/60:.1f} minutes")
    logger.info(f"   ğŸ“„ PDF conversion: {pdf_time:.2f}s")
    logger.info(f"   ğŸ” OCR processing: {ocr_time:.2f}s")
    logger.info(f"   ğŸ“ Merge & save: {(total_time - pdf_time - ocr_time):.2f}s")

if __name__ == "__main__":
    start_time = time.time()
    pdf2finalmarkdown(PDF, OUT_DIR, MODEL, API, OUT_MD, max_workers=OCR_MAX_WORKERS)
    end_time = time.time()
    logger.info(f"â±ï¸  Total execution time: {end_time - start_time:.2f} seconds")